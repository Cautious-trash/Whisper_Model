{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1026907268.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install openai-whisper PyQt5 sounddevice numpy torch\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Installing Necessary Libraries\n",
    "pip install openai-whisper PyQt5 sounddevice numpy torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\jainr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\jainr\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Libraries  and PYQT for making Interface\n",
    "import sys\n",
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QLabel, QVBoxLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"base\")  # Choose from 'tiny', 'base', 'small', 'medium', 'large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechToTextApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.label = QLabel('Click \"Start\" to begin recording your voice.', self)\n",
    "        self.result_label = QLabel('', self)\n",
    "        self.start_button = QPushButton('Start', self)\n",
    "        self.stop_button = QPushButton('Stop', self)\n",
    "\n",
    "        self.start_button.clicked.connect(self.start_recording)\n",
    "        self.stop_button.clicked.connect(self.stop_recording)\n",
    "        self.stop_button.setEnabled(False)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        layout.addWidget(self.start_button)\n",
    "        layout.addWidget(self.stop_button)\n",
    "        layout.addWidget(self.result_label)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "        self.setWindowTitle('Real-Time Speech to Text using Whisper')\n",
    "        self.setGeometry(100, 100, 500, 250)\n",
    "\n",
    "        self.audio_data = []\n",
    "        self.samplerate = 16000\n",
    "\n",
    "    def callback(self, indata, frames, time, status):\n",
    "        if status:\n",
    "            print(status)\n",
    "        self.audio_data.append(indata.copy())\n",
    "\n",
    "    def start_recording(self):\n",
    "        self.label.setText(\"Recording... Speak Now.\")\n",
    "        self.audio_data = []\n",
    "        self.start_button.setEnabled(False)\n",
    "        self.stop_button.setEnabled(True)\n",
    "        self.stream = sd.InputStream(callback=self.callback, channels=1, samplerate=self.samplerate)\n",
    "        self.stream.start()\n",
    "\n",
    "    def stop_recording(self):\n",
    "        self.stream.stop()\n",
    "        self.start_button.setEnabled(True)\n",
    "        self.stop_button.setEnabled(False)\n",
    "        self.label.setText(\"Processing audio...\")\n",
    "        self.process_audio()\n",
    "\n",
    "    def process_audio(self):\n",
    "        audio_data = np.concatenate(self.audio_data, axis=0).flatten()\n",
    "        audio_data = (audio_data * 32767).astype(np.int16)  # Convert to int16 format\n",
    "\n",
    "        # Save as temporary WAV for Whisper input\n",
    "        sf.write(\"temp_audio.mp3\", audio_data, self.samplerate)\n",
    "\n",
    "        # Transcribe using Whisper\n",
    "        result = model.transcribe(\"temp_audio.mp3\", language=\"hi\")  # Detect Hindi or any other language\n",
    "        transcription = result['text']\n",
    "\n",
    "        self.result_label.setText(f\"Transcription: {transcription}\")\n",
    "        self.label.setText(\"Recording completed. Press Start for another.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QApplication' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the application\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mQApplication\u001b[49m(sys\u001b[38;5;241m.\u001b[39margv)\n\u001b[0;32m      4\u001b[0m     ex \u001b[38;5;241m=\u001b[39m SpeechToTextApp()\n\u001b[0;32m      5\u001b[0m     ex\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QApplication' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the application\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = SpeechToTextApp()\n",
    "    ex.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
